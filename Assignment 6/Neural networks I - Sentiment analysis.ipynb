{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc9be56",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b3b52",
   "metadata": {},
   "source": [
    "In this exercise we use the IMDb-dataset, which we will use to perform a sentiment analysis. The code below assumes that the data is placed in the same folder as this notebook. We see that the reviews are loaded as a pandas dataframe, and print the beginning of the first few reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67da3bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                                                   0\n",
      "0  bromwell high is a cartoon comedy . it ran at ...\n",
      "1  story of a man who has unnatural feelings for ...\n",
      "2  homelessness  or houselessness as george carli...\n",
      "3  airport    starts as a brand new luxury    pla...\n",
      "4  brilliant over  acting by lesley ann warren . ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv('reviews.txt', header=None)\n",
    "labels = pd.read_csv('labels.txt', header=None)\n",
    "Y = (labels=='positive').astype(np.int_)\n",
    "\n",
    "print(type(reviews))\n",
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982b946",
   "metadata": {},
   "source": [
    "**(a)** Split the reviews and labels in test, train and validation sets. The train and validation sets will be used to train your model and tune hyperparameters, the test set will be saved for testing. Use the `CountVectorizer` from `sklearn.feature_extraction.text` to create a Bag-of-Words representation of the reviews. Only use the 10,000 most frequent words (use the `max_features`-parameter of `CountVectorizer`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf07ee9",
   "metadata": {},
   "source": [
    "**(b)** Explore the representation of the reviews. How is a single word represented? How about a whole review?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2638fce",
   "metadata": {},
   "source": [
    "**(c)** Train a neural network with a single hidden layer on the dataset, tuning the relevant hyperparameters to optimize accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd327a6",
   "metadata": {},
   "source": [
    "**(d)** Test your sentiment-classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd44ee62",
   "metadata": {},
   "source": [
    "**(e)** Use the classifier to classify a few sentences you write yourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import seed, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "X = reviews.data\n",
    "y = labels.target\n",
    "Y = to_categorical(y, num_classes)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y)\n",
    "input_size = X[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "model = Sequential() # initialize a neural network\n",
    "model.add(Dense(units = 32, activation='tanh', input_dim=input_size)) # add a hidden layer\n",
    "model.add(Dense(units = num_classes, activation='softmax')) #add the output layer\n",
    "\n",
    "sgd = optimizers.SGD(learning_rate = 0.1)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs = 10, batch_size = 50, verbose = 0, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
